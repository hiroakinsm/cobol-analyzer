COBOLソースコード解析結果から、ドキュメントを生成する仕組みをRAGで構築したい
ただし、できる限り解析や結果導出は、説明責任や結果の一貫性保持の観点からRAG以外の技術を用いるものとする
sentence transformer等、AI自体の採用はこれに限らず進めるものとする

COBOLソースコードの内容解析結果は、ASTとメタデータをデータベースに格納済である。
解析済ソースに関連する、ASTとメタデータはそれぞれMongoDBに格納され
解析タスクに関連する情報はPostgreSQLDBに格納されている。
これらのデータを参照し、新規に作成するテーブル等に必要なカラム等を作成しデータを記録する。
参照先である、これら解析済みデータは絶対に上書きしない

それぞれのサーバーの接続情報は以下の通り

◆アプリケーションサーバー
172.16.0.27
user : administrator
password : kanami1001!

※前工程における1次解析済みのソースコード保存先→これらもインプットとして利用する
/home/koopa-cobol-analyzer/completed

◆AI/RAG/MLサーバー
172.16.0.19
user : administrator
password : kanami1001!

◆Webサーバー
172.16.0.25
user : administrator
password : kanami1001!

◆SQLデータベースサーバー
172.16.0.13
db_name : cobol_analysis_db
db_usr : cobana_admin
password : Kanami1001!

・テーブル情報
logs : ログを格納【既存テーブル読み出しは禁止】
metadata : メタデータを格納【既存テーブル読み出しは禁止】

◆ベクトルデータベースサーバー
172.16.0.15
user : administrator
password : kanami1001!

◆NoSQLデータベースサーバー
172.16.0.17
user : administrator
password : kanami1001!

user : administrator
db : cobol_ast_db
collection : 
ast_collection : 対象ソース毎にASTを格納【読み込みのみ】
source_info : 対象ソース毎にメタデータを格納【読み込みのみ】

なお、解析済のソースコードは、以下に格納されている。

◆アプリケーションサーバー
172.16.0.27
user : administrator
password : Kanami1001!

前工程である、ソースコード解析およびAST生成を目的としたjavaプログラムを実装済み
koopaと、オリジナルプログラムソースを実行する

解析済のソースコードファイル保存先
/home/koopa-cobol-analyzer/completed

これら情報を基に、以下処理を実施する

◆172.16.0.27上に、venv仮想環境を構築し、アプリケーションロジックを実装する

開発venv仮想環境上に、python3.9にて実装するものとする。
実行環境は、/home/administrator/cobol-analyzer上に構築する

◆172.16.0.19上に、venv仮想環境を構築し、RAGを実装する

◆172.16.0.19上に、venv仮想環境を構築し、sentence transformer実行環境を実装する
→RAG以外のAIで、sentence transformer以外が必要であれば、それらも同じく実装する

RAG実装と適用についての基本的な考え方は以下の通り
1.Llama3.1 8B-Instructを4ビット量子圧縮する
2.構築するRAGからは、インターネット参照可とする
3.以下を各々生成し、結果はMongoDBの新たなコレクションに、ソース毎に作成する
4.キャッシュ等にはベクトルデータベースを使用し、本処理用に新たなコレクションを作成するものとする
4.1 ASTからフローチャートをMermaid記法で作成する
4.2 ASTからシーケンス図をMermaid記法で作成する
4.3 ASTからコードメトリクスを生成し、マークダウン記法で作成する
4.4 ASTからコードセキュリティ上の指摘事項を作成し、マークダウン記法で作成する
4.5 ダッシュボードやドキュメントに掲載するコンテンツで、RAGでなければ作成できないコンテンツ生成や、文章の調製を実施する
4.6 コンテンツ生成の根拠データは必ず解析済データとし、ハルシネーションはどの様な状況下においても発生させない

【単一解析とサマリ解析】
単一解析は単一のCOBOLソース、AST、メタデータに対して実施し、解析結果はデータベースに項目毎に記録する
解析処理経過はログに記録する
サマリ解析は、複数のCOBOLソースを指定し、それらが単一解析を実施済みであれば、サマリ解析IDを払い出し、付帯するAST、メタデータ、解析結果を基に、総合的な解析を実施し、解析結果はデータベースに項目毎に記録する
解析処理経過はログに記録する


マスタに関しては、以下を検討しているがこれらに限定されない
【環境マスタ】
システム動作環境に関するマスタ

【単一解析マスタ】
単一解析の処理の制御項目に対し、値を設定するマスタ

【サマリ解析マスタ】
サマリ解析の処理の制御項目に対し、値を設定するマスタ

【ダッシュボードマスタ】
ダッシュボード生成および出力に関する制御項目に対し、値を設定するマスタ

【ドキュメントマスタ】
ドキュメント生成および出力に関する制御項目に対し、値を設定するマスタ

【ベンチマークマスタ】
解析には項目毎に、ユーザー標準、業界における標準、各種規格上の標準を設定可能とし、

【ダッシュボード】
◆基本仕様
1.データベースに格納されたソース単位の情報を基に、以下ダッシュボードを作成し画面上に出力する
1.1 ソースファイル単位で画面を生成し、木構造とする
1.2 画面サイズは1920x1080ピクセルを標準サイズとし、それ以外のサイズに対応できる様レスポンシブデザインとする
1.3 ダッシュボードの目的は以下構造となっている
  ・プロジェクト全体の情報および進捗表示
  ・解析目的が単一のCOBOLソースとしての、解析結果表示
  ・解析目的を複数のCOBOLソースとしての、これら解析サマリ表示
→複数のCOBOLソースを解析対象とする場合、まず対象となるCOBOLソースを個別に解析し
→これら解析結果から、サマリを作成すると共にその内容を対象とする解析を実施し結果を表示する
1.2 テーマを「ソースコード解析結果」として、作成年月日、対象ソースファイル名をヘッダとして表示する
1.3 以下構造にしたがい画面を生成するものとし、対象データが存在しない場合でも省略しない
1.4 チャート等、画面に収まらないものはクリックすると拡大表示する様にする

【ドキュメント】
◆基本仕様
1.データベースに格納されたソース単位の情報を基に、以下ドキュメントを作成する
1.1 PDFでフォーマット
1.2 表紙を作成し、テーマを「ソースコード解析結果報告」として、作成年月日、対象ソースファイル名を記載する
1.3 目次を作成し、各ページのフッターにページ番号を掲載する

【ベンチマークについて】
仮に解析処理において、ベンチマーク上ルール違反が認められたとしても、以下は変更や修正は一切してはならず、厳に禁止する。
ただし、修正案の検討と作成、解析結果としての提示は処理の目的内となりこれは必要となる。
・COBOLソース
・JCLソース
・AST（COBOL）
・JCLソースから生成したAST
・アセンブラから生成したAST
・バッチから生成したAST
・ソースの外部データベース連携から生成したAST
・ソースの画面関連から生成したAST
・ソースのフォーム関連から生成したAST
